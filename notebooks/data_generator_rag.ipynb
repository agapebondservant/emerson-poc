{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "836a44bc-97c6-4076-80ac-54357e547848",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "from docling.document_converter import DocumentConverter\n",
    "import boto3\n",
    "import os\n",
    "from sdg_hub.core.flow import FlowRegistry\n",
    "from sdg_hub.core.blocks import BlockRegistry\n",
    "import pypdfium2 as pdfium\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.vectorstores import LanceDB\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.graph_vectorstores import GraphVectorStoreRetriever\n",
    "from langchain_core.documents import Document\n",
    "from lancedb.rerankers import LinearCombinationReranker\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, MarkdownHeaderTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "import lancedb\n",
    "from huggingface_hub import snapshot_download\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings, SentenceTransformerEmbeddings\n",
    "from transformers import AutoTokenizer\n",
    "from enum import Enum\n",
    "import traceback\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d361dcb2-e2f8-4ba6-996c-45eb1b1e955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_url = os.getenv('AWS_S3_ENDPOINT')\n",
    "access_key_id = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "secret_access_key = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "config = boto3.session.Config(signature_version='s3v4')\n",
    "bucket = os.getenv(\"AWS_S3_BUCKET\")\n",
    "source_path = 'pdf/'\n",
    "target_path = 'pdf'\n",
    "target_path_chapters = 'pdf_chunked'\n",
    "target_path_markdown = 'markdown'\n",
    "CODE_LANGUAGE='ColdFusion'\n",
    "\n",
    "embedding_model = SentenceTransformerEmbeddings(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\", \n",
    "    model_kwargs={\"trust_remote_code\":True\n",
    "})\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"openai/gpt-oss-20b\", # os.getenv('QWEN25CODER_MODEL_ID'),\n",
    "    api_key=os.getenv('OPENROUTER_TOKEN'),\n",
    "    base_url=os.getenv('OPENROUTER_API_BASE'),\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "vectorstore_connection = lancedb.connect(f\"s3://data/lancedb-graphrag\",\n",
    "    storage_options={\n",
    "        \"endpoint_url\": endpoint_url,\n",
    "        \"aws_access_key_id\": access_key_id,\n",
    "        \"aws_secret_access_key\": secret_access_key,\n",
    "        \"s3_force_path_style\": \"true\",\n",
    "        \"allow_http\": \"true\",\n",
    "    }\n",
    ")\n",
    "\n",
    "vectorstore = LanceDB(\n",
    "    mode=\"append\",\n",
    "    embedding=embedding_model,\n",
    "    connection=vectorstore_connection,\n",
    ")\n",
    "\n",
    "minio = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url=endpoint_url,\n",
    "    aws_access_key_id=access_key_id,\n",
    "    aws_secret_access_key=secret_access_key,\n",
    "    config=boto3.session.Config(signature_version='s3v4')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5582024-6e56-460b-9b63-46052324d8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(target_path, exist_ok=True)\n",
    "    os.makedirs(target_path_chapters, exist_ok=True)\n",
    "    files = minio.list_objects_v2(Bucket=bucket, Prefix=source_path)\n",
    "    if 'Contents' in files:\n",
    "        for obj in files['Contents']:\n",
    "            file = obj['Key']\n",
    "            minio.download_file(bucket, file, f\"{target_path}/{file.split('/')[-1]}\")\n",
    "            print(f\"File '{source_path}' downloaded successfully to {target_path}/{file.split('/')[-1]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933ae816-170e-4e63-ad4b-bec590ccabe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chapter_ranges(sourcefilename, do_print=True):\n",
    "    \"\"\"\n",
    "    Returns a list of (beginPage, endPage) ranges for chunks that represent chapters in the given pdf.\n",
    "    \"\"\"\n",
    "    print(\"Getting chapter ranges...\\n\")\n",
    "    \n",
    "    pdf = pdfium.PdfDocument(sourcefilename)\n",
    "    ranges = []\n",
    "    begin, end = None, None\n",
    "    \n",
    "    for item in pdf.get_toc():\n",
    "        state = \"*\" if item.n_kids == 0 else \"-\" if item.is_closed else \"+\"\n",
    "        target = \"?\" if item.page_index is None else item.page_index+1\n",
    "        boundary = None\n",
    "        \n",
    "        if item.page_index and ((item.n_kids == 0 and item.level < 2) or item.level == 2):\n",
    "            if begin is not None:\n",
    "                end = item.page_index - 1\n",
    "                boundary = [begin, max(begin, end)]\n",
    "                ranges.append(boundary)\n",
    "            begin = item.page_index\n",
    "            \n",
    "        if do_print:\n",
    "            if boundary:\n",
    "                print(\"    \" * 2 +  f\"(Pages {(boundary[0]+1)} - {(boundary[1]+1)})\" + \"\\n\")\n",
    "            print((\"    \" * item.level) + f\"[{state}] {item.title} -> {target}  # {item.view_mode} {item.view_pos}\")\n",
    "    return ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31779365-eb6d-42d1-97a7-b79867cce081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_chapters(sourcefilename, targetfilename, pagerange):\n",
    "    \"\"\"\n",
    "    Splits the pdf into chapters using the provided page ranges.\n",
    "    Returns the name of the new pdf chunk.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        source_pdf = pdfium.PdfDocument(sourcefilename)\n",
    "        new_pdf = pdfium.PdfDocument.new()\n",
    "    \n",
    "        print(f\"Retrieving chapter...{targetfilename}, Pages {pagerange[0]} to {pagerange[1]}\")\n",
    "        new_page_index = new_pdf.import_pages(source_pdf, pages=list(range(pagerange[0], pagerange[1]+1)))\n",
    "        new_pdf.save(targetfilename)\n",
    "        \n",
    "        source_pdf.close()\n",
    "        new_pdf.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving {targetfilename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4742de-d2d3-401f-9cf7-ad24d49714d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_markdown(pdffile, markdownfile):\n",
    "    \"\"\"\n",
    "    Converts the pdf into a markdown file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Converting {pdffile} to markdown...\")\n",
    "        \n",
    "        converter = DocumentConverter()\n",
    "        \n",
    "        result = converter.convert(pdffile)\n",
    "        \n",
    "        markdown_output = result.document.export_to_markdown()\n",
    "\n",
    "        with open(markdownfile, \"w\") as file:\n",
    "            file.write(markdown_output)\n",
    "\n",
    "        print(f\"{markdownfile} generated.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving {markdownfile}: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e3a1d3-7f48-4f27-afc5-f6eb3428c852",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeType(Enum):\n",
    "    \"\"\"\n",
    "    Types of entity relationships\n",
    "    \"\"\"\n",
    "    MARKDOWN_SECTION = \"markdown-section\"\n",
    "    CODE_TO_MARKDOWN = \"markdown\"\n",
    "    CODE_TO_TOPICS = \"topics\"\n",
    "    CODE_TO_KEYWORDS = \"keywords\"\n",
    "    CODE_TO_TAGS = \"tags\"\n",
    "    CODE_TO_FUNCTIONS = \"functions\"\n",
    "    CODE_TO_STRUCTURE = \"structure\"\n",
    "    CODE_TO_SUMMARY = \"summary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1852b034-b023-4830-b4a1-d92a3cc92843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_code_section(content):\n",
    "    \"\"\"\n",
    "    Strips out code sections of file.\n",
    "    \"\"\"\n",
    "    code_sections = re.findall(r'```([^`]+)```', content, re.DOTALL)\n",
    "    return code_sections\n",
    "\n",
    "def extract_keywords(content):\n",
    "    \"\"\"\n",
    "    Extract keywords from the provided content.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        code_task = f\"\"\"\n",
    "        analyze this text and provide 10 one-word keywords that are connected to the text\n",
    "        \"\"\"\n",
    "        code_instructions = \"\"\"\n",
    "            1.  **Format your response clearly and concisely** as a comma-delimited list.\n",
    "        \"\"\"\n",
    "        keywords = text_generation_tool([content], CODE_LANGUAGE, code_task, code_instructions)\n",
    "        keywords = keywords[0].content.strip()\n",
    "        keywords = [k.strip() for k in keywords.split(',')]\n",
    "        return keywords\n",
    "    except Exception as e:\n",
    "        print(f\"Error while extracting keywords: {e}\")\n",
    "        traceback.print_exc() \n",
    "        return []\n",
    "\n",
    "def text_generation_tool(code_sections, code_language, code_task, code_instructions):\n",
    "    system_template = \"\"\"\n",
    "    You are an expert software engineer with extensive experience in {code_language}.\n",
    "    Your task is to {code_task}.\n",
    "    **Instructions:**\n",
    "    {code_instructions}\n",
    "    **Text to analyze:**\n",
    "    \"\"\"\n",
    "    system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            system_message_prompt,\n",
    "            HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    inputs = [{\"input\": section, \n",
    "               \"code_language\": code_language,\n",
    "               \"code_task\": code_task,\n",
    "               \"code_instructions\": code_instructions} \n",
    "              for section in code_sections]\n",
    "    chain = prompt | llm\n",
    "    responses = chain.batch(inputs)\n",
    "    return responses\n",
    "    \n",
    "\"\"\"\n",
    "1. Markdown sections\n",
    "\"\"\"\n",
    "def build_markdown_section(file):\n",
    "    \"\"\"\n",
    "    Generates markdown section chunks from the file and stores them in the vector database.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Parsing markdown {file}...\")\n",
    "        filecontent = None\n",
    "        with open(file, mode=\"r\") as f: \n",
    "            filecontent = f.read()\n",
    "        headers_to_split = [(\"#\", \"Header 1\"), (\"##\", \"Header 2\"),(\"###\", \"Header 3\")]\n",
    "        text_splitter = MarkdownHeaderTextSplitter(headers_to_split, strip_headers=False)\n",
    "        splits = text_splitter.split_text(filecontent)\n",
    "        \n",
    "        if strip_code_section(filecontent):\n",
    "            docs = [Document(page_content=s.page_content, \n",
    "                             metadata= {\"source\": file,\n",
    "                                       \"parent\": os.urandom(36).hex()} | s.metadata | {\"keywords\": extract_keywords(s.page_content)} )\n",
    "                    for s in splits]\n",
    "            # print(docs)\n",
    "            print(f\"Saving {len(docs)} docs...\")\n",
    "            vectorstore.add_documents(documents=docs)\n",
    "            print(f\"{file} markdown saved to db, starting code-to-text mappings...\")\n",
    "    \n",
    "            saved_docs = []\n",
    "            for doc in docs:\n",
    "                sections = strip_code_section(doc.page_content)\n",
    "\n",
    "                if sections:\n",
    "                    # Generate code-to-markdown chunks\n",
    "                    saved_docs += build_code_to_markdown(sections, doc) or []\n",
    "            \n",
    "                    # Generate code-to-concept chunks\n",
    "                    saved_docs += build_code_to_topics(sections, doc) or []\n",
    "            \n",
    "                    # Generate code-to-tags chunks\n",
    "                    saved_docs += build_code_to_tags(sections, doc) or []\n",
    "            \n",
    "                    # Generate code-to-functions chunks\n",
    "                    saved_docs += build_code_to_functions(sections, doc) or []\n",
    "            \n",
    "                    # Generate code-to-structure chunks\n",
    "                    saved_docs += build_code_to_structure(sections, doc) or []\n",
    "            \n",
    "                    # Generate code-to-summary chunks\n",
    "                    saved_docs += build_code_to_summary(sections, doc) or []\n",
    "    \n",
    "                    print(f\"Number of code-to-text mappings generated: {len(saved_docs)}....\")\n",
    "                    vectorstore.add_documents(documents=saved_docs)\n",
    "                    print(\"Code-to-text mappings saved.\")\n",
    "            print(f\"Code to text mappings completed for {file}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving {file}: {e}\")\n",
    "        traceback.print_exc() \n",
    "\n",
    "\"\"\"\n",
    "2. Code-to-markdown sections\n",
    "\"\"\"\n",
    "def build_code_to_markdown(sections, doc):\n",
    "    \"\"\"\n",
    "    Generates code-to-markdown mappings from the list of code sections using a parent-child hierarchy \n",
    "    and stores them in the vector database.\n",
    "    \"\"\"\n",
    "    content=[f\"***Markdown***:\\n{doc.page_content}\" for section in sections]\n",
    "    docs = [Document(page_content=c, \n",
    "                         metadata=({\"parent\": doc.id} | doc.metadata | {\"keywords\": extract_keywords(c)})) \n",
    "            for c in content]\n",
    "    return docs\n",
    "\n",
    "\"\"\"\n",
    "3. Code-to-topics\n",
    "\"\"\"\n",
    "def build_code_to_topics(sections, doc):\n",
    "    \"\"\"\n",
    "    Generates code-to-topic mappings from the list of code sections using a parent-child hierarchy \n",
    "    and stores them in the vector database.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        code_task = f\"\"\"\n",
    "        analyze this code and generate an outline of general {CODE_LANGUAGE} topics that are connected to the code\n",
    "        \"\"\"\n",
    "        code_instructions = \"\"\"\n",
    "            1.  **Provide a list of the topics that you find.**\n",
    "            2.  **Format your response clearly and concisely** using a numbered list.\n",
    "        \"\"\"\n",
    "        responses = text_generation_tool(sections, CODE_LANGUAGE, code_task, code_instructions)\n",
    "        docs = [Document(page_content=f\"***Topics***:\\n{r.content}\", \n",
    "                         metadata=({\"parent\": doc.id} | doc.metadata | {\"keywords\": extract_keywords(r)})) \n",
    "                for i, r in enumerate(responses)]\n",
    "        return docs\n",
    "    except Exception as e:\n",
    "        print(f\"Error in CODE_TO_TOPICS: {e}\")\n",
    "        traceback.print_exc() \n",
    "        \n",
    "\n",
    "\"\"\"\n",
    "4. Code-to-tags\n",
    "\"\"\"\n",
    "def build_code_to_tags(sections, doc):\n",
    "    \"\"\"\n",
    "    Generates code-to-Coldfusion tag mappings from the list of code sections using a parent-child hierarchy \n",
    "    and stores them in the vector database.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        code_task = f\"\"\"\n",
    "        analyze this code and generate an outline of components that you can find in the code\n",
    "        \"\"\"\n",
    "        code_instructions = \"\"\"\n",
    "            1.  **Analyze the code for:** Various ColdFusion tags, HTML / CSS elements, and other similar code elements.\n",
    "            2.  **Provide a detailed explanation of your findings.**\n",
    "            3.  **Format your response clearly and concisely** using a numbered list.\n",
    "        \"\"\"\n",
    "        responses = text_generation_tool(sections, CODE_LANGUAGE, code_task, code_instructions)\n",
    "        docs = [Document(page_content=f\"***Components***:\\n{r.content}\", \n",
    "                         metadata=({\"parent\": doc.id} | doc.metadata | {\"keywords\": extract_keywords(r)})) \n",
    "                for i, r in enumerate(responses)]\n",
    "        return docs\n",
    "    except Exception as e:\n",
    "        print(f\"Error in code_to_tags: {e}\")\n",
    "        traceback.print_exc() \n",
    "\n",
    "\"\"\"\n",
    "5. Code-to-functions\n",
    "\"\"\"\n",
    "def build_code_to_functions(sections, doc):\n",
    "    \"\"\"\n",
    "    Generates code-to-function mappings from the list of code sections using a parent-child hierarchy \n",
    "    and stores them in the vector database.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        code_task = f\"\"\"\n",
    "        analyze this code and generate an outline of functions that you can find in the code\n",
    "        \"\"\"\n",
    "        code_instructions = \"\"\"\n",
    "            1.  **Analyze the code for:** Any functions that you can locate in the code.\n",
    "            2.  **Provide a detailed explanation of your findings.**\n",
    "            3.  **Format your response clearly and concisely** using a numbered list.\n",
    "        \"\"\"\n",
    "        responses = text_generation_tool(sections, CODE_LANGUAGE, code_task, code_instructions)\n",
    "        docs = [Document(page_content=f\"***Functions***:\\n{r.content}\", \n",
    "                         metadata=({\"parent\": doc.id} | doc.metadata | {\"keywords\": extract_keywords(r)})) \n",
    "                for i, r in enumerate(responses)]\n",
    "        return docs\n",
    "    except Exception as e:\n",
    "        print(f\"Error in code_to_functions: {e}\")\n",
    "        traceback.print_exc() \n",
    "\n",
    "\"\"\"\n",
    "6. Code-to-structure\n",
    "\"\"\"\n",
    "def build_code_to_structure(sections, doc):\n",
    "    \"\"\"\n",
    "    Generates code-to-structure mappings from the list of code sections using a parent-child hierarchy \n",
    "    and stores them in the vector database.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        code_task = f\"\"\"\n",
    "        describe the general structure of this code\n",
    "        \"\"\"\n",
    "        code_instructions = \"\"\"\n",
    "            1.  **Provide a detailed explanation of your findings.**\n",
    "            2.  **Format your response clearly and concisely** using bullet points.\n",
    "        \"\"\"\n",
    "        responses = text_generation_tool(sections, CODE_LANGUAGE, code_task, code_instructions)\n",
    "        docs = [Document(page_content=f\"Structure***:\\n{r.content}\", \n",
    "                         metadata=({\"parent\": doc.id} | doc.metadata | {\"keywords\": extract_keywords(r)})) \n",
    "                for i, r in enumerate(responses)]\n",
    "        return docs\n",
    "    except Exception as e:\n",
    "        print(f\"Error in code_to_structure: {e}\")\n",
    "        traceback.print_exc() \n",
    "        \n",
    "\"\"\"\n",
    "7. Code-to-summary\n",
    "\"\"\"\n",
    "def build_code_to_summary(sections, doc):\n",
    "    \"\"\"\n",
    "    Generates code-to-summary mappings from the list of code sections using a parent-child hierarchy \n",
    "    and stores them in the vector database.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        code_task = f\"\"\"\n",
    "        provide a summary of this code\n",
    "        \"\"\"\n",
    "        code_instructions = \"\"\"\n",
    "            1.  **Provide a concise summary, including the potential business purpose and use cases for the code.**\n",
    "            2.  **Format your response clearly and concisely** using bullet points.\n",
    "        \"\"\"\n",
    "        responses = text_generation_tool(sections, CODE_LANGUAGE, code_task, code_instructions)\n",
    "        docs = [Document(page_content=f\"***Summary***:\\n{r.content}\", \n",
    "                         metadata=({\"parent\": doc.id} | doc.metadata | {\"keywords\": extract_keywords(r)})) \n",
    "                for i, r in enumerate(responses)]\n",
    "        return docs\n",
    "    except Exception as e:\n",
    "        print(f\"Error in code_to_summary: {e}\")\n",
    "        traceback.print_exc() \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fa715b-c426-486a-a027-68965169e29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir(target_path) if \".pdf\" in f]\n",
    "for file in files:\n",
    "    ranges = get_chapter_ranges(f\"{target_path}/{file}\", do_print=False)\n",
    "    for idx, _range in enumerate(ranges):\n",
    "        pdf = f\"{target_path_chapters}/{idx}_{file}\"\n",
    "        md = f\"{target_path_markdown}/{idx}_{file.replace('.pdf', '.md')}\"\n",
    "        split_chapters(f\"{target_path}/{file}\", pdf, _range)\n",
    "        # convert_to_markdown(pdf, md)\n",
    "        build_markdown_section(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928983d0-7e32-4142-bb4a-d88572358f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table = vectorstore_connection.open_table('vectorstore')\n",
    "# table_schema = table.schema\n",
    "# print(f\"Schema for table '{table.name}':\")\n",
    "# print(\"-\" * 30)\n",
    "# for field in table_schema:\n",
    "#     print(f\" - Column: '{field.name}'\")\n",
    "#     print(f\"   Type: {field.type}\")\n",
    "#     print(f\"   Nullable: {field.nullable}\")\n",
    "\n",
    "# print(f\"\\nFull PyArrow Schema:\\n{table_schema}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4291e9a8-c095-47c0-ae93-7dd31e81602f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
